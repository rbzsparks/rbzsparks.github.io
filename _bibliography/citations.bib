%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Bobby Sparks at 2023-07-23


%% Saved with string encoding Unicode (UTF-8) 

@article{sparks2025,
	author = {Sparks, Robert Z and Keene, Grace E and Perez, Malia J and Pha, Victoria, and Tan, Alvin W M Yin, Zi and Long, Bria and Marchman, Virginia A and Frank, Michael C},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	title = {The ChildView Dataset: Longitudinal Tracking of Preschoolers’ Naturalistic Classroom Experiences Using Egocentric Videos.},
	year = {in prep}}

@article{frank2025,
	author = {Frank, Michael C and Marchman, Virginia A and Bergey, Claire A and Boyce, Veronica and Braginsky, Mika and Kachergis, George and Mankewitz, Jess and Meylan, Stephen and Prystawski, Ben and Ram, Nilam and Sparks, Robert Z and Steffan, Adrian and Tan, Alvin W M and Zettersten, Martin},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	title = {Continuous developmental changes in word recognition support language learning across early childhood},
	website = {https://osf.io/preprints/psyarxiv/dtv2f_v1},
	osf = {https://osf.io/z8pur/},
	preprint = {https://osf.io/preprints/psyarxiv/dtv2f_v1},
	abstract = {Being a fluent language user involves recognizing words as they unfold in time. How does this skill develop over the course of early 
	childhood? And how does facility in word recognition relate to the growth of vocabulary knowledge? We address these questions using data from 
	Peekbank, an open database of experiments measuring children's eye movements during early word recognition. Combining 24 datasets from almost 
	2,000 children ages 1--6 years, we show that word recognition becomes faster, more accurate, and less variable across development, consistent 
	with a process of skill learning. Factor analysis reveals covariation of word recognition speed and accuracy with children's vocabulary size 
	in cross-sectional analysis. Further, across a range of longitudinal models, speed, accuracy, and vocabulary show coupled growth such that 
	children with faster word recognition tend to show faster vocabulary growth. Together, these findings support the view that word recognition 
	is a skill that develops gradually across early childhood and that this skill plays a role in supporting early language learning.},
	year = {under review}}

@inproceedings{sparks2024,
	author = {Sparks, Robert Z and Long, Bria and Keene, Grace E and Perez, Malia J and Tan, Alvin W M and Marchman, Virginia A and Frank, Michael C},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	booktitle = {Proceedings of the 46th Annual Conference of the Cognitive Science Society},
	title = {Characterizing Contextual Variation in Children’s Preschool Language Environment Using Naturalistic Egocentric Videos},
	website = {https://escholarship.org/uc/item/94j9m5v1},
	pdf = {https://rbzsparks.github.io/papers/2024__Sparks_CogSci.pdf},
	osf = {https://osf.io/967zv/},
	preprint = {https://osf.io/preprints/psyarxiv/y75zu},
	abstract = {What structures children’s early language environment? Large corpora of child-centered naturalistic recordings provide an important 
	window into this question, but most available data centers on young children within the home or in lab contexts interacting primarily with a single 
	caregiver. Here, we characterize children’s language experience in a very different kind of environment: the preschool classroom. Children ages 3 – 5 
	years (N = 26) wore a head-mounted camera in their preschool class, yielding a naturalistic, egocentric view of children’s everyday experience across 
	many classroom activity contexts (e.g., sand play, snack time), with >30 hours of video data. Using semi-automatic transcriptions (227,624 words), we 
	find that activity contexts in the preschool classroom vary in both the quality and quantity of the language that children both hear and produce. 
	Together, these findings reinforce prior theories emphasizing the contribution of activity contexts in structuring the variability in children’s early 
	learning environments.},
	year = {2024}}

@inproceedings{long2025,
	author = {Long*, Bria and Sparks*, Robert Z, and Xiang*, Violet and Stojanov*, Stefan and Yin, Zi and Keene, Grace E and Tan, Alvin W M and Feng, Steven Y and and Nag, Auddithio and Zhuang, Chengxu and Marchman, Virginia A and Yamins, Daniel L K and Frank, Michael C},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	booktitle = {Proceedings of the 8th Annual Conference on Cognitive Computational Neuroscience},
	title = {The BabyView dataset: High-resolution egocentric videos of infants’ and young children’s everyday experiences},
	website = {https://arxiv.org/abs/2406.10447},
	abstract = {Human children far exceed modern machine learning algorithms in their sample efficiency, achieving high performance in key domains with much 
	less data than current models. This "data gap" is a key challenge both for building intelligent artificial systems and for understanding human development. 
	Egocentric video capturing children's experience—their "training data''—is a key ingredient for comparison of humans and models and for the development of 
	algorithmic innovations to bridge this gap. Yet there are few such datasets available, and extant data are low-resolution, have limited metadata, and 
	importantly, represent only a small set of children's experiences. Here, we provide the first release of a large developmental egocentric video dataset—the 
	BabyView dataset—recorded using a high-resolution camera with a large vertical field-of-view and gyroscope/accelerometer data. This 868 hour dataset includes 
	egocentric videos from children spanning 5 months to 3 years of age in longitudinal, at-home contexts. We provide gold-standard annotations for the evaluation 
	of speech transcription, speaker diarization, and human pose estimation, and evaluate models in each of these domains. We train self-supervised language and 
	vision models and evaluate their transfer to out-of-distribution tasks including syntactic structure learning, object recognition, depth estimation, and image 
	segmentation. Although performance in each scales with dataset size, overall performance is relatively lower than when models are trained on curated datasets, 
	especially in the visual domain. Our dataset stands as an open challenge for robust, human-like AI systems: how can such systems achieve human-levels of success 
	on the same scale and distribution of training data as humans?},
	year = {2025}}

@article{bohn2025,
	author = {Bohn, Manuel and Prein, Julia and Ayikoru, Agnes and Bednarski, Florian M and Dzabatou, Ardain and Frank, Michael C and Henderson, Annette M E and Isabella, Joan and Kalbitz, Josefine and Kanngeisser, Patricia and Keşşafoğlu, Dilara and Köymen, Bahar and Manrique-Hernandez, Maria V and Magazi, Shirley, and Mújica-Manrique, Lizbeth and Ohlendorf, Julia and Olaoba, Damilola, and Pieters, Wesley R and Pope-Caldwell, Sarah and Slocombe, Katie, and Sparks, Robert Z and Sunderarajan, Jahnavi and Vieira, Wilson and Zhang, Zhen and Zong, Yufei and Stengelin, Roman and Haun, Daniel B M},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	booktitle = {},
	title = {A universal of human social cognition: Children from 17 communities process gaze in similar ways},
	journal = {Child Development},
	website = {https://osf.io/preprints/psyarxiv/z3ahv_v2},
	preprint = {https://osf.io/preprints/psyarxiv/z3ahv_v2},
	abstract = {Theoretical accounts assume that key features of human social cognition are universal. Here we focus on gaze-following, the bedrock of social interactions and coordinated activities, to test this claim. In this comprehensive 
	cross-cultural study spanning five continents and 17 distinct cultural communities, we examined the development of gaze-following in early childhood. We identified key processing signatures through a computational model that assumes that 
	participants follow an individual’s gaze by estimating a vector emanating from the eye-center through the pupil. Using a single reliable touchscreen-based task, we found these signatures in all communities, suggesting that children 
	worldwide processed gaze in highly similar ways. Absolute differences in performance between groups are accounted for by a cross-culturally consistent relationship between children’s exposure to touchscreens and their performance in the 
	task. These results provide strong evidence for a universal process underlying a foundational socio-cognitive ability in humans that can be reliably inferred even in the presence of cultural variation in overt behavior.},
	year = {in press}}

@preprint{boyce2025,
	author = {Boyce, Veronica and Sparks, Robert Z and Mofor, Yannick, and Frank, Michael C},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	booktitle = {Poster at the Annual Meeting of the Cognitive Science Society},
	title = {Preschoolers can form conventional pacts with each other to communicate about novel referents},
	osf = {https://osf.io/7d3ne/},
	website = {https://osf.io/preprints/osf/dpgfw_v1},
	preprint = {https://osf.io/preprints/osf/dpgfw_v1},
	abstract = {Learning language requires learning not only the content of language, but also how to use language to communicate. 
	Iterated reference games provide a window into such skills, requiring rich communication as participants converge on mutually 
	understandable names for initially novel referents. Some early experiments are interpreted as evidence that 4-5-year-old children
	cannot converge to the mutually understandable names needed to communicate in an iterated reference game. Here, we revisit young
	children's referential communicative abilities using a simpler, child-friendly paradigm. Across 51 pairs of children, we found 
	that 4-5-year-olds successfully established reference with each other. Children were 85% accurate, and they often used 
	descriptions similar to their partner's. These findings suggest that children’s capacity to construct effective referring 
	expressions in novel contexts emerges earlier than once thought, consistent with the view that children show early pragmatic 
	competence in supportive contexts.},
	year = {2025}}

@article{frank2024,
	author = {Frank, Michael C and Baumgartner, Heidi and Braginsky, Mika and Kachergis, George and Lightbody, Amy and Sparks, Robert Z and Zhu, Rebecca and Dodge, Kenneth A and Cubillo, Ana},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	website = {https://osf.io/preprints/psyarxiv/namx2_v2},
	title = {Learning Variability Network Exchange (LEVANTE): A global framework for measuring children’s learning variability through collaborative data sharing},
	preprint = {https://osf.io/preprints/psyarxiv/namx2_v2},
	abstract = {Despite the ubiquity of variation in child development within individuals, across groups, and across tasks, timescales, and contexts, dominant methods in developmental science and education research still favor group averages, 
	short snapshots of time, and single environments. These methods cannot provide evidence about variability or potential interactions among different dimensions of variability. The Learning Variability Network Exchange (LEVANTE) is a framework 
	designed to enable coordinated data collection by diverse individual research teams worldwide, with the goal of measuring children’s variability within and across individuals, groups, and cultures. The measure set developed for LEVANTE aims to 
	capture variability in learning outcomes (literacy and numeracy) as well as core cognitive constructs (language, reasoning, executive function, spatial cognition) and social constructs (social cognition, caregiver engagement, relations with peers),
	 with each measure selected based on length, psychometric properties, cross-cultural applicability, and age span. LEVANTE will yield a large, open access longitudinal dataset for long-term research use. This repository will not only facilitate 
	 the science of learning variability, but also constitute the backbone of a larger multidisciplinary research network working toward improving children’s learning and development globally.},
	year = {under review}}

@article{prein2025,
	author = {Prein, Julia and Bednarski, Florian M and Dzabatou, Ardain and Frank, Michael C and Henderson, Annette M E and Isabella, Joan and Kalbitz, Josefine and Kanngeisser, Patricia and Keşşafoğlu, Dilara and Köymen, Bahar and Manrique-Hernandez, Maria V and Magazi, Shirley, and Mújica-Manrique, Lizbeth and Ohlendorf, Julia and Olaoba, Damilola, and Pieters, Wesley R and Pope-Caldwell, Sarah and Sen, Umay and Slocombe, Katie, and Sparks, Robert Z and Stengelin, Roman and Sunderarajan, Jahnavi and Sutherland, Kirsten and Tusiime, Florence, and Vieira, Wilson and Zhang, Zhen and Zong, Yufei and Haun, Daniel B M and Bohn, Manuel},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	booktitle = {},
	journal = {Advances in Methods and Practices in Psychological Science},
	title = {Measuring variation in gaze following across communities, ages, and individuals — a showcase of the TANGO–CC},
	preprint = {https://osf.io/preprints/psyarxiv/fcq2g},
	doi = {10.1177/25152459241308170},
	website = {https://journals.sagepub.com/doi/10.1177/25152459241308170},
	abstract = {Cross-cultural studies are crucial for investigating the cultural variability and universality of cognitive developmental processes. 
	However, cross-cultural assessment tools in cognition across languages and communities are limited. In this article, we describe a gaze-following 
	task designed to measure basic social cognition across individuals, ages, and communities (the Task for Assessing iNdividual differences in Gaze 
	understanding-Open-Cross-Cultural; TANGO-CC). The task was developed and psychometrically assessed in one cultural setting and, with input of local 
	collaborators, adapted for cross-cultural data collection. Minimal language demands and the web-app implementation allow fast and easy contextual 
	adaptations to each community. TANGO-CC captures individual- and community-level variation and shows good internal consistency in a data set of 
	2.5- to 11-year-old children from 17 diverse communities. Within-communities variation outweighed between-communities variation. We provide an 
	open-source website for researchers to customize and use the task (https://ccp-odc.eva.mpg.de/tango-cc). TANGO-CC can be used to assess basic 
	social cognition in diverse communities and provides a roadmap for researching community-level and individual-level differences across cultures.},
	year = {2025}}

@article{chuey2024,
	author = {Chuey, Aaron and Sparks, Robert Z and Wistreich, Suzannah and Gweon, Hyowon},
	date-added = {2024-06-13 16:15:56 +0200},
	date-modified = {2024-06-13 16:15:56 +0200},
	booktitle = {},
	title = {Young Children Identify Knowledgeable Speakers Using Causal Influence},
	year = {in prep}}

@thesis{sparks2022,
	author = {Sparks, Robert Z and Chuey, Aaron and Gweon, Hyowon},
	date-added = {2023-07-24 16:15:56 +0200},
	date-modified = {2023-07-24 16:15:56 +0200},
	title = {Preschool-Aged Children Can Infer What Speakers Know Based on How They Influence Others},
	journal = {Stanford Digital Repository},
	website = {https://purl.stanford.edu/xx316hn9817},
	doi = {10.25740/xx316hn9817},
	pdf = {https://rbzsparks.github.io/papers/2022_honors_thesis.pdf},
	abstract = {How do we know what others know? Prior work has examined
how children use evidence about isolated agents, like their
perceptual access and actions, to infer what they know. However,
humans are rarely fully isolated; instead, we are often
surrounded by others whom we interact with, influence, and
are influenced by. In these contexts, we can use a speaker’s
communication and the way it causes a listener to behave to
infer what that speaker knows - even if we do not know the
specific content of what was communicated. The present studies
investigated how preschool-aged children use two pieces of
evidence about listeners to reason about what speakers know:
changes in the outcomes of a listener’s actions following communication
(Study 1) and changes in a listener’s actions themselves
following communication (Study 2). In both studies,
children observed two scenarios where a listener failed to activate
a toy before succeeding. In Study 1, children observed
a speaker produce nonsense language towards a listener after
they failed but before they succeeded to activate a toy, as
well as another speaker who spoke to a listener prior to initial
failure. In Study 2, children observed a speaker communicate
with a listener before a distinct change in action, followed by
success, as well as another speaker who communicated with a
listener resulting in no distinct change in action, followed by
success. When asked which speaker knows how to make the
toy work, 5 year-olds chose the speaker who appeared to cause
the listener to succeed (Study 1) or change their action (Study
2). These results suggest that preschool-aged children are sensitive
to the way speakers influence others via communication
and can use evidence of that influence to infer what speakers
know. More broadly, these studies highlight children’s ability
to reason about the knowledge of one agent (a speaker) based
primarily on evidence about another agent (a listener).},
	year = {2022}}

@article{long2023,
	author = {Long, Bria and Kachergis, George and Marchman, Virginia A and Radwan, Samaher F and Sparks, Robert Z and Xiang, Violet and Zhuang, Chengxu and Hsu, Oliver and Newman, Brett and Yamins, Daniel LK and Frank, Michael C},
	date-added = {2023-07-24 16:15:56 +0200},
	date-modified = {2023-07-24 16:15:56 +0200},
	journal = {Behavior Research Methods},
	title = {The BabyView Camera: Designing a New Head-mounted Camera to Capture Children’s Early Social and Visual Environments},
	website = {https://link.springer.com/article/10.3758/s13428-023-02206-1},
	preprint = {https://psyarxiv.com/238jk/},
	osf = {https://osf.io/kwvxu/},
	doi = {10.3758/s13428-023-02206-1},
	abstract = {Head-mounted cameras have been used in developmental psychology research for more than a
decade to provide a rich and comprehensive view of what infants see during their everyday
experiences. However, variation between these devices has limited the field’s ability to compare
results across studies and across labs. Further, the video data captured by these cameras to date
has been relatively low-resolution, limiting how well machine learning algorithms can operate
over these rich video data. Here, we provide a well-tested and easily constructed design for a
head-mounted camera assembly—the BabyView—developed in collaboration with Daylight
Design, LLC., a professional product design firm. The BabyView collects high-resolution video,
accelerometer, and gyroscope data from children approximately 6 - 30 months of age via a
GoPro camera custom mounted on a soft child-safety helmet. The BabyView also captures a
large, portrait-oriented vertical field-of-view that encompasses both children’s interactions with
objects and with their social partners. We detail our protocols for video data management and
for handling sensitive data from home environments. We also provide customizable materials
for onboarding families with the BabyView. We hope that these materials will encourage the
wide adoption of the BabyView, allowing the field to collect high-resolution data that can link
children’s everyday environments with their learning outcomes.},
	year = {2023}}

@inproceedings{chuey2023,
	author = {Chuey, Aaron and Sparks, Robert Z and Gweon, Hyowon},
	date-added = {2023-07-24 16:15:56 +0200},
	date-modified = {2023-07-24 16:15:56 +0200},
	booktitle = {{Proceedings of the 45th Annual Conference of the Cognitive Science Society}},
	pages = {230235},
	title = {Young children can identify knowledgeable speakers from their causal influence over listeners},
	website = {https://escholarship.org/uc/item/9qh630dn},
	pdf = {https://rbzsparks.github.io/papers/2023_Chuey_Sparks_Gweon_CogSci.pdf},
	osf = {https://osf.io/derxp/?view_only=d3ad5730e321405da0e5347dfb35a3f0},
	abstract = {Prior work demonstrates an early-emerging understanding of
how speakers can alter listeners’ minds and actions. Yet, an abstract
understanding of communication entails more than forward
inferences about its influence on the listener; it also supports
inverse inferences about the speaker based on its causal
influence over the listener. Can children reason about the
minds of speakers based on their causal influence over listeners?
Across three studies, children viewed two communicative
exchanges where a listener attempted to activate a toy; we manipulated
when speakers communicated (Exp.1), how listeners’
subsequent actions changed (Exp.2), and whether speakers
spoke or sneezed (Exp.3). By 5 years of age, children inferred
the speaker who appeared to cause the listener to succeed was
more knowledgeable, but only when they produced speech.
These results suggest children can reason causally about the
sources of communication, identifying knowledgeable speakers
based on their influence over a listener’s actions and their
outcomes.},
	year = {2023}}


